{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXtKbnOAeMli",
        "outputId": "c785fffa-2584-4f0a-9125-703410dbc1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "--- Train with AdamW ---\n",
            "Epoch 1/150, Train Acc: 5.20%, Val Acc: 9.49%, Test Acc: 7.30%\n",
            "Epoch 1/150, Train Loss: 4.2837, Val Loss: 4.0080, Test Loss: 4.1196\n",
            "Epoch 2/150, Train Acc: 9.86%, Val Acc: 13.06%, Test Acc: 9.89%\n",
            "Epoch 2/150, Train Loss: 3.9541, Val Loss: 3.8159, Test Loss: 3.9346\n",
            "Epoch 3/150, Train Acc: 12.23%, Val Acc: 14.75%, Test Acc: 11.05%\n",
            "Epoch 3/150, Train Loss: 3.8084, Val Loss: 3.6924, Test Loss: 3.8541\n",
            "Epoch 4/150, Train Acc: 13.89%, Val Acc: 16.68%, Test Acc: 13.80%\n",
            "Epoch 4/150, Train Loss: 3.7017, Val Loss: 3.5855, Test Loss: 3.7368\n",
            "Epoch 5/150, Train Acc: 15.54%, Val Acc: 17.28%, Test Acc: 15.04%\n",
            "Epoch 5/150, Train Loss: 3.6085, Val Loss: 3.5107, Test Loss: 3.6572\n",
            "Epoch 6/150, Train Acc: 16.80%, Val Acc: 18.94%, Test Acc: 15.22%\n",
            "Epoch 6/150, Train Loss: 3.5228, Val Loss: 3.4184, Test Loss: 3.6246\n",
            "Epoch 7/150, Train Acc: 18.06%, Val Acc: 20.96%, Test Acc: 15.88%\n",
            "Epoch 7/150, Train Loss: 3.4490, Val Loss: 3.3571, Test Loss: 3.5948\n",
            "Epoch 8/150, Train Acc: 19.05%, Val Acc: 21.78%, Test Acc: 17.55%\n",
            "Epoch 8/150, Train Loss: 3.3901, Val Loss: 3.2852, Test Loss: 3.5172\n",
            "Epoch 9/150, Train Acc: 20.25%, Val Acc: 22.47%, Test Acc: 17.83%\n",
            "Epoch 9/150, Train Loss: 3.3289, Val Loss: 3.2470, Test Loss: 3.4502\n",
            "Checkpoint saved at epoch 10: ./checkpoint_epoch_10.pth\n",
            "Epoch 10/150, Train Acc: 21.01%, Val Acc: 23.15%, Test Acc: 17.44%\n",
            "Epoch 10/150, Train Loss: 3.2810, Val Loss: 3.2056, Test Loss: 3.4728\n",
            "Epoch 11/150, Train Acc: 21.94%, Val Acc: 23.69%, Test Acc: 18.45%\n",
            "Epoch 11/150, Train Loss: 3.2407, Val Loss: 3.1563, Test Loss: 3.4147\n",
            "Epoch 12/150, Train Acc: 22.69%, Val Acc: 23.98%, Test Acc: 20.07%\n",
            "Epoch 12/150, Train Loss: 3.1999, Val Loss: 3.1528, Test Loss: 3.3142\n",
            "Epoch 13/150, Train Acc: 23.16%, Val Acc: 24.76%, Test Acc: 19.83%\n",
            "Epoch 13/150, Train Loss: 3.1660, Val Loss: 3.1008, Test Loss: 3.3229\n",
            "Epoch 14/150, Train Acc: 24.34%, Val Acc: 25.47%, Test Acc: 21.04%\n",
            "Epoch 14/150, Train Loss: 3.1238, Val Loss: 3.0830, Test Loss: 3.2785\n",
            "Epoch 15/150, Train Acc: 24.52%, Val Acc: 26.39%, Test Acc: 21.55%\n",
            "Epoch 15/150, Train Loss: 3.0930, Val Loss: 3.0355, Test Loss: 3.2528\n",
            "Epoch 16/150, Train Acc: 25.35%, Val Acc: 27.54%, Test Acc: 21.51%\n",
            "Epoch 16/150, Train Loss: 3.0575, Val Loss: 2.9905, Test Loss: 3.2497\n",
            "Epoch 17/150, Train Acc: 26.05%, Val Acc: 27.13%, Test Acc: 23.21%\n",
            "Epoch 17/150, Train Loss: 3.0285, Val Loss: 2.9943, Test Loss: 3.1567\n",
            "Epoch 18/150, Train Acc: 26.61%, Val Acc: 27.98%, Test Acc: 22.97%\n",
            "Epoch 18/150, Train Loss: 3.0008, Val Loss: 2.9523, Test Loss: 3.1625\n",
            "Epoch 19/150, Train Acc: 27.21%, Val Acc: 28.13%, Test Acc: 23.14%\n",
            "Epoch 19/150, Train Loss: 2.9663, Val Loss: 2.9408, Test Loss: 3.1369\n",
            "Checkpoint saved at epoch 20: ./checkpoint_epoch_20.pth\n",
            "Epoch 20/150, Train Acc: 27.59%, Val Acc: 29.58%, Test Acc: 23.55%\n",
            "Epoch 20/150, Train Loss: 2.9420, Val Loss: 2.8899, Test Loss: 3.1409\n",
            "Epoch 21/150, Train Acc: 27.98%, Val Acc: 29.62%, Test Acc: 24.86%\n",
            "Epoch 21/150, Train Loss: 2.9202, Val Loss: 2.8650, Test Loss: 3.0633\n",
            "Epoch 22/150, Train Acc: 28.70%, Val Acc: 29.96%, Test Acc: 24.55%\n",
            "Epoch 22/150, Train Loss: 2.8882, Val Loss: 2.8533, Test Loss: 3.0860\n",
            "Epoch 23/150, Train Acc: 28.88%, Val Acc: 30.46%, Test Acc: 24.65%\n",
            "Epoch 23/150, Train Loss: 2.8677, Val Loss: 2.8111, Test Loss: 3.0644\n",
            "Epoch 24/150, Train Acc: 29.65%, Val Acc: 31.15%, Test Acc: 26.23%\n",
            "Epoch 24/150, Train Loss: 2.8442, Val Loss: 2.8001, Test Loss: 3.0082\n",
            "Epoch 25/150, Train Acc: 30.02%, Val Acc: 31.31%, Test Acc: 25.65%\n",
            "Epoch 25/150, Train Loss: 2.8172, Val Loss: 2.7829, Test Loss: 3.0143\n",
            "Epoch 26/150, Train Acc: 30.32%, Val Acc: 31.91%, Test Acc: 26.30%\n",
            "Epoch 26/150, Train Loss: 2.8005, Val Loss: 2.7514, Test Loss: 3.0041\n",
            "Epoch 27/150, Train Acc: 30.87%, Val Acc: 31.53%, Test Acc: 27.84%\n",
            "Epoch 27/150, Train Loss: 2.7727, Val Loss: 2.7687, Test Loss: 2.9413\n",
            "Epoch 28/150, Train Acc: 30.97%, Val Acc: 32.28%, Test Acc: 26.93%\n",
            "Epoch 28/150, Train Loss: 2.7554, Val Loss: 2.7319, Test Loss: 2.9534\n",
            "Epoch 29/150, Train Acc: 31.55%, Val Acc: 32.45%, Test Acc: 27.55%\n",
            "Epoch 29/150, Train Loss: 2.7344, Val Loss: 2.7143, Test Loss: 2.9323\n",
            "Checkpoint saved at epoch 30: ./checkpoint_epoch_30.pth\n",
            "Epoch 30/150, Train Acc: 31.90%, Val Acc: 33.04%, Test Acc: 27.34%\n",
            "Epoch 30/150, Train Loss: 2.7122, Val Loss: 2.6834, Test Loss: 2.9442\n",
            "Epoch 31/150, Train Acc: 32.54%, Val Acc: 32.94%, Test Acc: 27.80%\n",
            "Epoch 31/150, Train Loss: 2.6884, Val Loss: 2.6792, Test Loss: 2.9166\n",
            "Epoch 32/150, Train Acc: 32.96%, Val Acc: 33.30%, Test Acc: 27.78%\n",
            "Epoch 32/150, Train Loss: 2.6714, Val Loss: 2.6672, Test Loss: 2.9182\n",
            "Epoch 33/150, Train Acc: 33.27%, Val Acc: 33.58%, Test Acc: 28.90%\n",
            "Epoch 33/150, Train Loss: 2.6510, Val Loss: 2.6533, Test Loss: 2.8773\n",
            "Epoch 34/150, Train Acc: 33.62%, Val Acc: 33.93%, Test Acc: 29.75%\n",
            "Epoch 34/150, Train Loss: 2.6331, Val Loss: 2.6469, Test Loss: 2.8476\n",
            "Epoch 35/150, Train Acc: 33.96%, Val Acc: 34.19%, Test Acc: 29.39%\n",
            "Epoch 35/150, Train Loss: 2.6191, Val Loss: 2.6442, Test Loss: 2.8484\n",
            "Epoch 36/150, Train Acc: 34.45%, Val Acc: 34.58%, Test Acc: 29.18%\n",
            "Epoch 36/150, Train Loss: 2.5924, Val Loss: 2.6218, Test Loss: 2.8455\n",
            "Epoch 37/150, Train Acc: 34.97%, Val Acc: 35.25%, Test Acc: 29.90%\n",
            "Epoch 37/150, Train Loss: 2.5764, Val Loss: 2.5942, Test Loss: 2.8224\n",
            "Epoch 38/150, Train Acc: 34.89%, Val Acc: 35.19%, Test Acc: 30.92%\n",
            "Epoch 38/150, Train Loss: 2.5622, Val Loss: 2.5942, Test Loss: 2.7803\n",
            "Epoch 39/150, Train Acc: 35.41%, Val Acc: 35.64%, Test Acc: 30.16%\n",
            "Epoch 39/150, Train Loss: 2.5475, Val Loss: 2.5657, Test Loss: 2.8075\n",
            "Checkpoint saved at epoch 40: ./checkpoint_epoch_40.pth\n",
            "Epoch 40/150, Train Acc: 35.75%, Val Acc: 35.22%, Test Acc: 30.87%\n",
            "Epoch 40/150, Train Loss: 2.5228, Val Loss: 2.5750, Test Loss: 2.7882\n",
            "Epoch 41/150, Train Acc: 36.32%, Val Acc: 35.80%, Test Acc: 30.82%\n",
            "Epoch 41/150, Train Loss: 2.5105, Val Loss: 2.5491, Test Loss: 2.7767\n",
            "Epoch 42/150, Train Acc: 36.52%, Val Acc: 36.44%, Test Acc: 30.76%\n",
            "Epoch 42/150, Train Loss: 2.5010, Val Loss: 2.5286, Test Loss: 2.7737\n",
            "Epoch 43/150, Train Acc: 36.66%, Val Acc: 36.43%, Test Acc: 30.98%\n",
            "Epoch 43/150, Train Loss: 2.4828, Val Loss: 2.5307, Test Loss: 2.7692\n",
            "Epoch 44/150, Train Acc: 36.99%, Val Acc: 36.29%, Test Acc: 32.47%\n",
            "Epoch 44/150, Train Loss: 2.4714, Val Loss: 2.5344, Test Loss: 2.7189\n",
            "Epoch 45/150, Train Acc: 37.74%, Val Acc: 36.58%, Test Acc: 31.41%\n",
            "Epoch 45/150, Train Loss: 2.4516, Val Loss: 2.5082, Test Loss: 2.7400\n",
            "Epoch 46/150, Train Acc: 37.53%, Val Acc: 37.40%, Test Acc: 30.60%\n",
            "Epoch 46/150, Train Loss: 2.4463, Val Loss: 2.4768, Test Loss: 2.7629\n",
            "Epoch 47/150, Train Acc: 38.26%, Val Acc: 37.48%, Test Acc: 31.75%\n",
            "Epoch 47/150, Train Loss: 2.4237, Val Loss: 2.4862, Test Loss: 2.7263\n",
            "Epoch 48/150, Train Acc: 37.94%, Val Acc: 37.38%, Test Acc: 32.43%\n",
            "Epoch 48/150, Train Loss: 2.4174, Val Loss: 2.4916, Test Loss: 2.7156\n",
            "Epoch 49/150, Train Acc: 38.19%, Val Acc: 37.71%, Test Acc: 32.13%\n",
            "Epoch 49/150, Train Loss: 2.4036, Val Loss: 2.4588, Test Loss: 2.7191\n",
            "Checkpoint saved at epoch 50: ./checkpoint_epoch_50.pth\n",
            "Epoch 50/150, Train Acc: 38.67%, Val Acc: 37.92%, Test Acc: 32.90%\n",
            "Epoch 50/150, Train Loss: 2.3965, Val Loss: 2.4590, Test Loss: 2.6606\n",
            "Epoch 51/150, Train Acc: 38.88%, Val Acc: 38.19%, Test Acc: 32.85%\n",
            "Epoch 51/150, Train Loss: 2.3798, Val Loss: 2.4641, Test Loss: 2.6876\n",
            "Epoch 52/150, Train Acc: 39.41%, Val Acc: 38.24%, Test Acc: 32.87%\n",
            "Epoch 52/150, Train Loss: 2.3689, Val Loss: 2.4459, Test Loss: 2.6749\n",
            "Epoch 53/150, Train Acc: 39.45%, Val Acc: 38.72%, Test Acc: 32.63%\n",
            "Epoch 53/150, Train Loss: 2.3634, Val Loss: 2.4180, Test Loss: 2.6948\n",
            "Epoch 54/150, Train Acc: 39.88%, Val Acc: 38.55%, Test Acc: 32.90%\n",
            "Epoch 54/150, Train Loss: 2.3480, Val Loss: 2.4366, Test Loss: 2.6742\n",
            "Epoch 55/150, Train Acc: 39.63%, Val Acc: 39.26%, Test Acc: 33.29%\n",
            "Epoch 55/150, Train Loss: 2.3403, Val Loss: 2.4144, Test Loss: 2.6693\n",
            "Epoch 56/150, Train Acc: 39.92%, Val Acc: 38.65%, Test Acc: 33.36%\n",
            "Epoch 56/150, Train Loss: 2.3296, Val Loss: 2.4252, Test Loss: 2.6586\n",
            "Epoch 57/150, Train Acc: 40.48%, Val Acc: 39.11%, Test Acc: 33.27%\n",
            "Epoch 57/150, Train Loss: 2.3203, Val Loss: 2.4068, Test Loss: 2.6586\n",
            "Epoch 58/150, Train Acc: 40.17%, Val Acc: 38.48%, Test Acc: 32.59%\n",
            "Epoch 58/150, Train Loss: 2.3116, Val Loss: 2.4034, Test Loss: 2.6993\n",
            "Epoch 59/150, Train Acc: 40.26%, Val Acc: 39.17%, Test Acc: 33.13%\n",
            "Epoch 59/150, Train Loss: 2.3051, Val Loss: 2.3890, Test Loss: 2.6798\n",
            "Checkpoint saved at epoch 60: ./checkpoint_epoch_60.pth\n",
            "Epoch 60/150, Train Acc: 40.93%, Val Acc: 39.31%, Test Acc: 32.75%\n",
            "Epoch 60/150, Train Loss: 2.2865, Val Loss: 2.4007, Test Loss: 2.6777\n",
            "Epoch 61/150, Train Acc: 41.02%, Val Acc: 39.87%, Test Acc: 33.41%\n",
            "Epoch 61/150, Train Loss: 2.2850, Val Loss: 2.3882, Test Loss: 2.6497\n",
            "Epoch 62/150, Train Acc: 41.03%, Val Acc: 39.58%, Test Acc: 33.76%\n",
            "Epoch 62/150, Train Loss: 2.2767, Val Loss: 2.3785, Test Loss: 2.6529\n",
            "Epoch 63/150, Train Acc: 41.30%, Val Acc: 39.29%, Test Acc: 33.83%\n",
            "Epoch 63/150, Train Loss: 2.2702, Val Loss: 2.3907, Test Loss: 2.6386\n",
            "Epoch 64/150, Train Acc: 41.59%, Val Acc: 39.32%, Test Acc: 34.20%\n",
            "Epoch 64/150, Train Loss: 2.2600, Val Loss: 2.3807, Test Loss: 2.6161\n",
            "Epoch 65/150, Train Acc: 41.74%, Val Acc: 39.59%, Test Acc: 33.67%\n",
            "Epoch 65/150, Train Loss: 2.2473, Val Loss: 2.3760, Test Loss: 2.6396\n",
            "Epoch 66/150, Train Acc: 41.87%, Val Acc: 39.94%, Test Acc: 33.96%\n",
            "Epoch 66/150, Train Loss: 2.2429, Val Loss: 2.3651, Test Loss: 2.6349\n",
            "Epoch 67/150, Train Acc: 41.98%, Val Acc: 39.73%, Test Acc: 34.73%\n",
            "Epoch 67/150, Train Loss: 2.2374, Val Loss: 2.3807, Test Loss: 2.6059\n",
            "Epoch 68/150, Train Acc: 42.37%, Val Acc: 40.37%, Test Acc: 34.04%\n",
            "Epoch 68/150, Train Loss: 2.2268, Val Loss: 2.3499, Test Loss: 2.6259\n",
            "Epoch 69/150, Train Acc: 42.70%, Val Acc: 39.91%, Test Acc: 34.53%\n",
            "Epoch 69/150, Train Loss: 2.2179, Val Loss: 2.3607, Test Loss: 2.6022\n",
            "Checkpoint saved at epoch 70: ./checkpoint_epoch_70.pth\n",
            "Epoch 70/150, Train Acc: 42.67%, Val Acc: 40.11%, Test Acc: 34.52%\n",
            "Epoch 70/150, Train Loss: 2.2160, Val Loss: 2.3535, Test Loss: 2.6137\n",
            "Epoch 71/150, Train Acc: 42.82%, Val Acc: 40.27%, Test Acc: 34.61%\n",
            "Epoch 71/150, Train Loss: 2.2067, Val Loss: 2.3477, Test Loss: 2.5902\n",
            "Epoch 72/150, Train Acc: 42.85%, Val Acc: 40.60%, Test Acc: 33.52%\n",
            "Epoch 72/150, Train Loss: 2.1975, Val Loss: 2.3483, Test Loss: 2.6588\n",
            "Epoch 73/150, Train Acc: 43.31%, Val Acc: 40.17%, Test Acc: 34.50%\n",
            "Epoch 73/150, Train Loss: 2.1898, Val Loss: 2.3493, Test Loss: 2.5913\n",
            "Epoch 74/150, Train Acc: 43.23%, Val Acc: 39.93%, Test Acc: 35.03%\n",
            "Epoch 74/150, Train Loss: 2.1877, Val Loss: 2.3393, Test Loss: 2.5830\n",
            "Epoch 75/150, Train Acc: 43.52%, Val Acc: 40.76%, Test Acc: 34.52%\n",
            "Epoch 75/150, Train Loss: 2.1840, Val Loss: 2.3304, Test Loss: 2.5967\n",
            "Epoch 76/150, Train Acc: 43.60%, Val Acc: 40.39%, Test Acc: 34.55%\n",
            "Epoch 76/150, Train Loss: 2.1724, Val Loss: 2.3303, Test Loss: 2.5926\n",
            "Epoch 77/150, Train Acc: 43.87%, Val Acc: 40.60%, Test Acc: 34.18%\n",
            "Epoch 77/150, Train Loss: 2.1645, Val Loss: 2.3322, Test Loss: 2.6080\n",
            "Epoch 78/150, Train Acc: 44.15%, Val Acc: 40.58%, Test Acc: 35.27%\n",
            "Epoch 78/150, Train Loss: 2.1585, Val Loss: 2.3249, Test Loss: 2.5731\n",
            "Epoch 79/150, Train Acc: 43.87%, Val Acc: 41.01%, Test Acc: 33.96%\n",
            "Epoch 79/150, Train Loss: 2.1589, Val Loss: 2.3191, Test Loss: 2.6192\n",
            "Checkpoint saved at epoch 80: ./checkpoint_epoch_80.pth\n",
            "Epoch 80/150, Train Acc: 43.95%, Val Acc: 40.83%, Test Acc: 35.17%\n",
            "Epoch 80/150, Train Loss: 2.1454, Val Loss: 2.3264, Test Loss: 2.5762\n",
            "Epoch 81/150, Train Acc: 44.22%, Val Acc: 40.86%, Test Acc: 35.33%\n",
            "Epoch 81/150, Train Loss: 2.1440, Val Loss: 2.3264, Test Loss: 2.5679\n",
            "Epoch 82/150, Train Acc: 44.51%, Val Acc: 41.11%, Test Acc: 34.99%\n",
            "Epoch 82/150, Train Loss: 2.1263, Val Loss: 2.3233, Test Loss: 2.5689\n",
            "Epoch 83/150, Train Acc: 44.56%, Val Acc: 41.46%, Test Acc: 34.60%\n",
            "Epoch 83/150, Train Loss: 2.1272, Val Loss: 2.3012, Test Loss: 2.5938\n",
            "Epoch 84/150, Train Acc: 44.40%, Val Acc: 41.22%, Test Acc: 34.94%\n",
            "Epoch 84/150, Train Loss: 2.1236, Val Loss: 2.3051, Test Loss: 2.5790\n",
            "Epoch 85/150, Train Acc: 44.67%, Val Acc: 41.28%, Test Acc: 35.84%\n",
            "Epoch 85/150, Train Loss: 2.1208, Val Loss: 2.3124, Test Loss: 2.5531\n",
            "Epoch 86/150, Train Acc: 44.98%, Val Acc: 41.31%, Test Acc: 34.88%\n",
            "Epoch 86/150, Train Loss: 2.1187, Val Loss: 2.3089, Test Loss: 2.5815\n",
            "Epoch 87/150, Train Acc: 45.30%, Val Acc: 41.32%, Test Acc: 35.64%\n",
            "Epoch 87/150, Train Loss: 2.1100, Val Loss: 2.3110, Test Loss: 2.5553\n",
            "Epoch 88/150, Train Acc: 45.00%, Val Acc: 41.49%, Test Acc: 35.27%\n",
            "Epoch 88/150, Train Loss: 2.1065, Val Loss: 2.2911, Test Loss: 2.5629\n",
            "Epoch 89/150, Train Acc: 45.30%, Val Acc: 41.54%, Test Acc: 35.66%\n",
            "Epoch 89/150, Train Loss: 2.1006, Val Loss: 2.2976, Test Loss: 2.5488\n",
            "Checkpoint saved at epoch 90: ./checkpoint_epoch_90.pth\n",
            "Epoch 90/150, Train Acc: 45.61%, Val Acc: 41.17%, Test Acc: 35.54%\n",
            "Epoch 90/150, Train Loss: 2.0897, Val Loss: 2.3004, Test Loss: 2.5637\n",
            "Epoch 91/150, Train Acc: 45.51%, Val Acc: 41.53%, Test Acc: 34.68%\n",
            "Epoch 91/150, Train Loss: 2.0922, Val Loss: 2.2981, Test Loss: 2.5899\n",
            "Epoch 92/150, Train Acc: 45.58%, Val Acc: 41.49%, Test Acc: 35.69%\n",
            "Epoch 92/150, Train Loss: 2.0863, Val Loss: 2.2959, Test Loss: 2.5382\n",
            "Epoch 93/150, Train Acc: 45.68%, Val Acc: 41.84%, Test Acc: 35.36%\n",
            "Epoch 93/150, Train Loss: 2.0842, Val Loss: 2.2889, Test Loss: 2.5591\n",
            "Epoch 94/150, Train Acc: 45.87%, Val Acc: 41.49%, Test Acc: 35.78%\n",
            "Epoch 94/150, Train Loss: 2.0703, Val Loss: 2.2984, Test Loss: 2.5507\n",
            "Epoch 95/150, Train Acc: 45.74%, Val Acc: 41.57%, Test Acc: 36.00%\n",
            "Epoch 95/150, Train Loss: 2.0747, Val Loss: 2.2877, Test Loss: 2.5460\n",
            "Epoch 96/150, Train Acc: 45.77%, Val Acc: 42.10%, Test Acc: 35.40%\n",
            "Epoch 96/150, Train Loss: 2.0687, Val Loss: 2.2840, Test Loss: 2.5597\n",
            "Epoch 97/150, Train Acc: 46.09%, Val Acc: 41.76%, Test Acc: 35.73%\n",
            "Epoch 97/150, Train Loss: 2.0676, Val Loss: 2.2818, Test Loss: 2.5503\n",
            "Epoch 98/150, Train Acc: 46.12%, Val Acc: 41.93%, Test Acc: 35.50%\n",
            "Epoch 98/150, Train Loss: 2.0590, Val Loss: 2.2860, Test Loss: 2.5515\n",
            "Epoch 99/150, Train Acc: 46.17%, Val Acc: 42.03%, Test Acc: 35.35%\n",
            "Epoch 99/150, Train Loss: 2.0557, Val Loss: 2.2795, Test Loss: 2.5538\n",
            "Checkpoint saved at epoch 100: ./checkpoint_epoch_100.pth\n",
            "Epoch 100/150, Train Acc: 46.22%, Val Acc: 41.81%, Test Acc: 35.68%\n",
            "Epoch 100/150, Train Loss: 2.0545, Val Loss: 2.2783, Test Loss: 2.5482\n",
            "Epoch 101/150, Train Acc: 46.16%, Val Acc: 42.23%, Test Acc: 36.19%\n",
            "Epoch 101/150, Train Loss: 2.0546, Val Loss: 2.2774, Test Loss: 2.5351\n",
            "Epoch 102/150, Train Acc: 46.37%, Val Acc: 42.23%, Test Acc: 35.75%\n",
            "Epoch 102/150, Train Loss: 2.0483, Val Loss: 2.2790, Test Loss: 2.5410\n",
            "Epoch 103/150, Train Acc: 46.55%, Val Acc: 41.95%, Test Acc: 36.22%\n",
            "Epoch 103/150, Train Loss: 2.0390, Val Loss: 2.2819, Test Loss: 2.5339\n",
            "Epoch 104/150, Train Acc: 46.38%, Val Acc: 41.95%, Test Acc: 36.15%\n",
            "Epoch 104/150, Train Loss: 2.0408, Val Loss: 2.2939, Test Loss: 2.5378\n",
            "Epoch 105/150, Train Acc: 46.72%, Val Acc: 42.32%, Test Acc: 36.21%\n",
            "Epoch 105/150, Train Loss: 2.0381, Val Loss: 2.2750, Test Loss: 2.5408\n",
            "Epoch 106/150, Train Acc: 46.75%, Val Acc: 42.36%, Test Acc: 35.33%\n",
            "Epoch 106/150, Train Loss: 2.0304, Val Loss: 2.2692, Test Loss: 2.5617\n",
            "Epoch 107/150, Train Acc: 46.48%, Val Acc: 42.32%, Test Acc: 35.79%\n",
            "Epoch 107/150, Train Loss: 2.0379, Val Loss: 2.2714, Test Loss: 2.5499\n",
            "Epoch 108/150, Train Acc: 46.73%, Val Acc: 41.94%, Test Acc: 35.92%\n",
            "Epoch 108/150, Train Loss: 2.0335, Val Loss: 2.2739, Test Loss: 2.5508\n",
            "Epoch 109/150, Train Acc: 47.02%, Val Acc: 42.21%, Test Acc: 36.05%\n",
            "Epoch 109/150, Train Loss: 2.0201, Val Loss: 2.2736, Test Loss: 2.5376\n",
            "Checkpoint saved at epoch 110: ./checkpoint_epoch_110.pth\n",
            "Epoch 110/150, Train Acc: 46.73%, Val Acc: 42.23%, Test Acc: 36.31%\n",
            "Epoch 110/150, Train Loss: 2.0291, Val Loss: 2.2699, Test Loss: 2.5315\n",
            "Epoch 111/150, Train Acc: 47.11%, Val Acc: 42.28%, Test Acc: 36.40%\n",
            "Epoch 111/150, Train Loss: 2.0238, Val Loss: 2.2692, Test Loss: 2.5318\n",
            "Epoch 112/150, Train Acc: 46.89%, Val Acc: 42.44%, Test Acc: 36.18%\n",
            "Epoch 112/150, Train Loss: 2.0191, Val Loss: 2.2637, Test Loss: 2.5350\n",
            "Epoch 113/150, Train Acc: 47.12%, Val Acc: 42.23%, Test Acc: 36.24%\n",
            "Epoch 113/150, Train Loss: 2.0233, Val Loss: 2.2679, Test Loss: 2.5274\n",
            "Epoch 114/150, Train Acc: 47.05%, Val Acc: 42.70%, Test Acc: 36.48%\n",
            "Epoch 114/150, Train Loss: 2.0135, Val Loss: 2.2658, Test Loss: 2.5231\n",
            "Epoch 115/150, Train Acc: 47.22%, Val Acc: 42.57%, Test Acc: 36.35%\n",
            "Epoch 115/150, Train Loss: 2.0113, Val Loss: 2.2673, Test Loss: 2.5285\n",
            "Epoch 116/150, Train Acc: 47.29%, Val Acc: 42.37%, Test Acc: 36.37%\n",
            "Epoch 116/150, Train Loss: 2.0075, Val Loss: 2.2623, Test Loss: 2.5271\n",
            "Epoch 117/150, Train Acc: 47.27%, Val Acc: 42.58%, Test Acc: 36.17%\n",
            "Epoch 117/150, Train Loss: 2.0022, Val Loss: 2.2649, Test Loss: 2.5292\n",
            "Epoch 118/150, Train Acc: 47.35%, Val Acc: 42.36%, Test Acc: 36.39%\n",
            "Epoch 118/150, Train Loss: 2.0077, Val Loss: 2.2647, Test Loss: 2.5230\n",
            "Epoch 119/150, Train Acc: 47.17%, Val Acc: 42.35%, Test Acc: 36.29%\n",
            "Epoch 119/150, Train Loss: 2.0059, Val Loss: 2.2620, Test Loss: 2.5251\n",
            "Checkpoint saved at epoch 120: ./checkpoint_epoch_120.pth\n",
            "Epoch 120/150, Train Acc: 47.25%, Val Acc: 42.55%, Test Acc: 36.45%\n",
            "Epoch 120/150, Train Loss: 2.0035, Val Loss: 2.2620, Test Loss: 2.5176\n",
            "Epoch 121/150, Train Acc: 47.57%, Val Acc: 42.48%, Test Acc: 35.96%\n",
            "Epoch 121/150, Train Loss: 2.0017, Val Loss: 2.2648, Test Loss: 2.5360\n",
            "Epoch 122/150, Train Acc: 47.74%, Val Acc: 42.33%, Test Acc: 36.66%\n",
            "Epoch 122/150, Train Loss: 1.9935, Val Loss: 2.2620, Test Loss: 2.5199\n",
            "Epoch 123/150, Train Acc: 47.64%, Val Acc: 42.34%, Test Acc: 36.41%\n",
            "Epoch 123/150, Train Loss: 1.9974, Val Loss: 2.2600, Test Loss: 2.5259\n",
            "Epoch 124/150, Train Acc: 47.70%, Val Acc: 42.49%, Test Acc: 36.26%\n",
            "Epoch 124/150, Train Loss: 1.9933, Val Loss: 2.2584, Test Loss: 2.5294\n",
            "Epoch 125/150, Train Acc: 47.70%, Val Acc: 42.35%, Test Acc: 36.09%\n",
            "Epoch 125/150, Train Loss: 1.9996, Val Loss: 2.2634, Test Loss: 2.5235\n",
            "Epoch 126/150, Train Acc: 47.59%, Val Acc: 42.64%, Test Acc: 36.20%\n",
            "Epoch 126/150, Train Loss: 1.9980, Val Loss: 2.2567, Test Loss: 2.5246\n",
            "Epoch 127/150, Train Acc: 47.93%, Val Acc: 42.52%, Test Acc: 36.28%\n",
            "Epoch 127/150, Train Loss: 1.9889, Val Loss: 2.2628, Test Loss: 2.5238\n",
            "Epoch 128/150, Train Acc: 47.62%, Val Acc: 42.51%, Test Acc: 36.28%\n",
            "Epoch 128/150, Train Loss: 1.9917, Val Loss: 2.2592, Test Loss: 2.5240\n",
            "Epoch 129/150, Train Acc: 47.45%, Val Acc: 42.52%, Test Acc: 36.25%\n",
            "Epoch 129/150, Train Loss: 1.9955, Val Loss: 2.2594, Test Loss: 2.5181\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split\n",
        "from google.colab import files\n",
        "\n",
        "# Training settings\n",
        "# betas, epochs and batch sized are fixed values\n",
        "epochs = 150\n",
        "batch_size = 64\n",
        "# weight decay and learning rate are adjustable\n",
        "weight_decay = 5e-4\n",
        "lr= 5e-5\n",
        "\n",
        "def compute_mean_std(dataset):\n",
        "    \"\"\"Compute the mean and std of CIFAR-100 dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: A dataset derived from `torch.utils.data.Dataset`,\n",
        "                 such as `cifar100_training_dataset` or `cifar100_test_dataset`.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing (mean, std) for the entire dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract images and labels\n",
        "    data_r = np.stack([np.array(dataset[i][0])[:, :, 0] for i in range(len(dataset))])\n",
        "    data_g = np.stack([np.array(dataset[i][0])[:, :, 1] for i in range(len(dataset))])\n",
        "    data_b = np.stack([np.array(dataset[i][0])[:, :, 2] for i in range(len(dataset))])\n",
        "\n",
        "    # Compute mean and std\n",
        "    mean = np.mean(data_r), np.mean(data_g), np.mean(data_b)\n",
        "    std = np.std(data_r), np.std(data_g), np.std(data_b)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "# Define LeNet-5 architecture\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 5 * 5)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42) # Set the seed for reproducibility\n",
        "torch.cuda.manual_seed_all(42) # Set the seed for reproducibility on GPU\n",
        "\n",
        "# use the same mean and std to add consistency to all datasets\n",
        "data = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mean, std = compute_mean_std(data)\n",
        "\n",
        "# Load and split CIFAR-100 dataset\n",
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert into tensor\n",
        "    transforms.Normalize(mean, std)  # Normalization\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(24),\n",
        "    transforms.Pad(4),\n",
        "    transforms.ToTensor(),  # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "valset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=val_transform)\n",
        "indices = torch.randperm(len(trainset))\n",
        "val_size = int(0.2*len(trainset))\n",
        "trainset = torch.utils.data.Subset(trainset, indices[:-val_size])\n",
        "valset = torch.utils.data.Subset(valset, indices[-val_size:])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model\n",
        "net_adamw = LeNet5().to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer and scheduler\n",
        "adamw_optimizer = optim.AdamW(net_adamw.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
        "scheduler_adamw = optim.lr_scheduler.CosineAnnealingLR(adamw_optimizer, T_max=150)\n",
        "'''\n",
        "# Load a checkpoint, if exists\n",
        "resume_training = True  # Put False if you want to start from scratch\n",
        "start_epoch = 0  # default starting epoch\n",
        "\n",
        "if resume_training and os.path.exists('checkpoint_epoch_30.pth'):\n",
        "    checkpoint = torch.load('checkpoint_epoch_30.pth', map_location=device)\n",
        "    net_adamw.load_state_dict(checkpoint['model_state_dict'])\n",
        "    adamw_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"Checkpoint caricato: riprendo da epoca {start_epoch}\")\n",
        "else:\n",
        "    print(\"Nessun checkpoint trovato, inizializzo da zero.\")\n",
        "'''\n",
        "\n",
        "# Training function\n",
        "def train_model(optimizer, scheduler, model, criterion, trainloader, valloader , testloader, device, epochs, save_checkpoint_interval=10):\n",
        "    train_losses, val_losses, test_losses = [], [], []\n",
        "    train_accuracies, val_accuracies, test_accuracies = [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += predicted.eq(labels).sum().item()\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_accuracy = 100. * correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct_val, total_val, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += predicted.eq(labels).sum().item()\n",
        "        val_loss /= len(valloader)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracy = 100. * correct_val / total_val\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Test\n",
        "        correct_test, total_test, test_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += predicted.eq(labels).sum().item()\n",
        "        test_loss /= len(testloader)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracy = 100. * correct_test / total_test\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Checkpointing\n",
        "        if (epoch + 1) % save_checkpoint_interval == 0:\n",
        "            checkpoint_filename = f'checkpoint_epoch_{epoch + 1}.pth'\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss.item(),\n",
        "            }\n",
        "            checkpoint_path = os.path.join('./', checkpoint_filename)\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f'Checkpoint saved at epoch {epoch + 1}: {checkpoint_path}')\n",
        "\n",
        "            #Download the checkpoint\n",
        "            #files.download(checkpoint_filename)\n",
        "\n",
        "        # print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%')\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "    return train_losses, val_losses, test_losses,  train_accuracies, val_accuracies, test_accuracies\n",
        "\n",
        "# Train model\n",
        "print(\"--- Train with AdamW ---\")\n",
        "adamw_train_loss, adamw_val_loss, adamw_test_loss, adamw_train_acc, adamw_val_acc, adamw_test_acc= train_model(adamw_optimizer, scheduler_adamw, net_adamw, criterion, trainloader, valloader, testloader, device, epochs)\n",
        "\n",
        "# Save model\n",
        "torch.save(net_adamw.state_dict(), 'net_adamw.pth')\n",
        "\n",
        "# Plot results\n",
        "# Plot Training Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_train_loss, label='Train Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Training Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_train_acc, label='Train Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_val_loss, label='Validation Loss')\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('val_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_val_acc, label='Validation Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('val_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_test_loss, label='Test Loss')\n",
        "plt.title('Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_test_acc, label='Test Accuracy')\n",
        "plt.title('Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_accuracy.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}