{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OXtKbnOAeMli",
        "outputId": "3ce3e56a-cb8f-4032-e1ee-4498b2fd053b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "--- Train with AdamW ---\n",
            "Epoch 1/150, Train Acc: 8.30%, Val Acc: 14.77%, Test Acc: 14.84%\n",
            "Epoch 1/150, Train Loss: 3.9969, Val Loss: 3.5948, Test Loss: 3.6132\n",
            "Epoch 2/150, Train Acc: 16.80%, Val Acc: 22.35%, Test Acc: 21.76%\n",
            "Epoch 2/150, Train Loss: 3.4738, Val Loss: 3.1970, Test Loss: 3.2043\n",
            "Epoch 3/150, Train Acc: 22.06%, Val Acc: 25.74%, Test Acc: 25.73%\n",
            "Epoch 3/150, Train Loss: 3.1822, Val Loss: 3.0004, Test Loss: 3.0060\n",
            "Epoch 4/150, Train Acc: 25.70%, Val Acc: 28.40%, Test Acc: 27.85%\n",
            "Epoch 4/150, Train Loss: 2.9813, Val Loss: 2.8784, Test Loss: 2.8837\n",
            "Epoch 5/150, Train Acc: 28.62%, Val Acc: 30.76%, Test Acc: 30.15%\n",
            "Epoch 5/150, Train Loss: 2.8213, Val Loss: 2.7640, Test Loss: 2.7484\n",
            "Epoch 6/150, Train Acc: 31.18%, Val Acc: 33.48%, Test Acc: 34.04%\n",
            "Epoch 6/150, Train Loss: 2.6969, Val Loss: 2.5953, Test Loss: 2.5822\n",
            "Epoch 7/150, Train Acc: 33.40%, Val Acc: 34.65%, Test Acc: 34.94%\n",
            "Epoch 7/150, Train Loss: 2.5957, Val Loss: 2.5505, Test Loss: 2.5320\n",
            "Epoch 8/150, Train Acc: 34.77%, Val Acc: 35.11%, Test Acc: 35.00%\n",
            "Epoch 8/150, Train Loss: 2.5219, Val Loss: 2.5504, Test Loss: 2.5438\n",
            "Epoch 9/150, Train Acc: 36.40%, Val Acc: 38.15%, Test Acc: 37.90%\n",
            "Epoch 9/150, Train Loss: 2.4494, Val Loss: 2.4106, Test Loss: 2.4002\n",
            "Checkpoint saved at epoch 10: ./checkpoint_epoch_10.pth\n",
            "Epoch 10/150, Train Acc: 37.32%, Val Acc: 37.82%, Test Acc: 37.58%\n",
            "Epoch 10/150, Train Loss: 2.3876, Val Loss: 2.4193, Test Loss: 2.4193\n",
            "Epoch 11/150, Train Acc: 38.82%, Val Acc: 38.73%, Test Acc: 38.36%\n",
            "Epoch 11/150, Train Loss: 2.3387, Val Loss: 2.3786, Test Loss: 2.3755\n",
            "Epoch 12/150, Train Acc: 40.14%, Val Acc: 39.36%, Test Acc: 39.30%\n",
            "Epoch 12/150, Train Loss: 2.2835, Val Loss: 2.3476, Test Loss: 2.3268\n",
            "Epoch 13/150, Train Acc: 40.76%, Val Acc: 39.45%, Test Acc: 39.81%\n",
            "Epoch 13/150, Train Loss: 2.2443, Val Loss: 2.3352, Test Loss: 2.3231\n",
            "Epoch 14/150, Train Acc: 41.28%, Val Acc: 39.23%, Test Acc: 39.67%\n",
            "Epoch 14/150, Train Loss: 2.2100, Val Loss: 2.3530, Test Loss: 2.3332\n",
            "Epoch 15/150, Train Acc: 42.35%, Val Acc: 40.15%, Test Acc: 40.03%\n",
            "Epoch 15/150, Train Loss: 2.1732, Val Loss: 2.3137, Test Loss: 2.2995\n",
            "Epoch 16/150, Train Acc: 43.53%, Val Acc: 40.70%, Test Acc: 41.27%\n",
            "Epoch 16/150, Train Loss: 2.1263, Val Loss: 2.2997, Test Loss: 2.2935\n",
            "Epoch 17/150, Train Acc: 43.56%, Val Acc: 42.07%, Test Acc: 41.72%\n",
            "Epoch 17/150, Train Loss: 2.1101, Val Loss: 2.2399, Test Loss: 2.2319\n",
            "Epoch 18/150, Train Acc: 44.64%, Val Acc: 41.59%, Test Acc: 41.30%\n",
            "Epoch 18/150, Train Loss: 2.0789, Val Loss: 2.2778, Test Loss: 2.2608\n",
            "Epoch 19/150, Train Acc: 45.12%, Val Acc: 42.59%, Test Acc: 41.82%\n",
            "Epoch 19/150, Train Loss: 2.0419, Val Loss: 2.2245, Test Loss: 2.2138\n",
            "Checkpoint saved at epoch 20: ./checkpoint_epoch_20.pth\n",
            "Epoch 20/150, Train Acc: 45.66%, Val Acc: 41.74%, Test Acc: 42.12%\n",
            "Epoch 20/150, Train Loss: 2.0159, Val Loss: 2.2641, Test Loss: 2.2650\n",
            "Epoch 21/150, Train Acc: 46.26%, Val Acc: 42.04%, Test Acc: 42.51%\n",
            "Epoch 21/150, Train Loss: 1.9940, Val Loss: 2.2511, Test Loss: 2.2293\n",
            "Epoch 22/150, Train Acc: 47.13%, Val Acc: 42.49%, Test Acc: 42.74%\n",
            "Epoch 22/150, Train Loss: 1.9587, Val Loss: 2.2362, Test Loss: 2.2133\n",
            "Epoch 23/150, Train Acc: 47.24%, Val Acc: 42.78%, Test Acc: 42.04%\n",
            "Epoch 23/150, Train Loss: 1.9450, Val Loss: 2.2355, Test Loss: 2.2256\n",
            "Epoch 24/150, Train Acc: 48.11%, Val Acc: 42.74%, Test Acc: 41.95%\n",
            "Epoch 24/150, Train Loss: 1.9212, Val Loss: 2.2423, Test Loss: 2.2332\n",
            "Epoch 25/150, Train Acc: 48.47%, Val Acc: 42.99%, Test Acc: 42.89%\n",
            "Epoch 25/150, Train Loss: 1.8905, Val Loss: 2.2219, Test Loss: 2.2038\n",
            "Epoch 26/150, Train Acc: 48.59%, Val Acc: 43.34%, Test Acc: 43.44%\n",
            "Epoch 26/150, Train Loss: 1.8797, Val Loss: 2.2177, Test Loss: 2.2162\n",
            "Epoch 27/150, Train Acc: 48.77%, Val Acc: 43.06%, Test Acc: 43.41%\n",
            "Epoch 27/150, Train Loss: 1.8575, Val Loss: 2.2053, Test Loss: 2.1929\n",
            "Epoch 28/150, Train Acc: 49.85%, Val Acc: 44.24%, Test Acc: 43.60%\n",
            "Epoch 28/150, Train Loss: 1.8339, Val Loss: 2.1841, Test Loss: 2.1811\n",
            "Epoch 29/150, Train Acc: 50.05%, Val Acc: 43.87%, Test Acc: 43.57%\n",
            "Epoch 29/150, Train Loss: 1.8220, Val Loss: 2.2030, Test Loss: 2.1956\n",
            "Checkpoint saved at epoch 30: ./checkpoint_epoch_30.pth\n",
            "Epoch 30/150, Train Acc: 50.63%, Val Acc: 44.24%, Test Acc: 43.71%\n",
            "Epoch 30/150, Train Loss: 1.8035, Val Loss: 2.1732, Test Loss: 2.1701\n",
            "Epoch 31/150, Train Acc: 50.92%, Val Acc: 43.64%, Test Acc: 43.90%\n",
            "Epoch 31/150, Train Loss: 1.7880, Val Loss: 2.2137, Test Loss: 2.1986\n",
            "Epoch 32/150, Train Acc: 51.55%, Val Acc: 44.08%, Test Acc: 44.44%\n",
            "Epoch 32/150, Train Loss: 1.7694, Val Loss: 2.2010, Test Loss: 2.1986\n",
            "Epoch 33/150, Train Acc: 51.46%, Val Acc: 43.53%, Test Acc: 43.90%\n",
            "Epoch 33/150, Train Loss: 1.7500, Val Loss: 2.2045, Test Loss: 2.1903\n",
            "Epoch 34/150, Train Acc: 52.04%, Val Acc: 43.90%, Test Acc: 44.49%\n",
            "Epoch 34/150, Train Loss: 1.7306, Val Loss: 2.2122, Test Loss: 2.1974\n",
            "Epoch 35/150, Train Acc: 52.15%, Val Acc: 44.25%, Test Acc: 43.84%\n",
            "Epoch 35/150, Train Loss: 1.7274, Val Loss: 2.2226, Test Loss: 2.2165\n",
            "Epoch 36/150, Train Acc: 52.59%, Val Acc: 44.09%, Test Acc: 44.40%\n",
            "Epoch 36/150, Train Loss: 1.7064, Val Loss: 2.1984, Test Loss: 2.1809\n",
            "Epoch 37/150, Train Acc: 52.93%, Val Acc: 44.44%, Test Acc: 44.21%\n",
            "Epoch 37/150, Train Loss: 1.6887, Val Loss: 2.1901, Test Loss: 2.1947\n",
            "Epoch 38/150, Train Acc: 53.21%, Val Acc: 44.73%, Test Acc: 44.78%\n",
            "Epoch 38/150, Train Loss: 1.6774, Val Loss: 2.2151, Test Loss: 2.2173\n",
            "Epoch 39/150, Train Acc: 53.26%, Val Acc: 44.80%, Test Acc: 45.08%\n",
            "Epoch 39/150, Train Loss: 1.6640, Val Loss: 2.2152, Test Loss: 2.2122\n",
            "Checkpoint saved at epoch 40: ./checkpoint_epoch_40.pth\n",
            "Epoch 40/150, Train Acc: 54.03%, Val Acc: 44.36%, Test Acc: 44.10%\n",
            "Epoch 40/150, Train Loss: 1.6488, Val Loss: 2.2237, Test Loss: 2.2241\n",
            "Epoch 41/150, Train Acc: 54.29%, Val Acc: 45.05%, Test Acc: 45.31%\n",
            "Epoch 41/150, Train Loss: 1.6332, Val Loss: 2.1798, Test Loss: 2.1799\n",
            "Epoch 42/150, Train Acc: 54.49%, Val Acc: 44.28%, Test Acc: 44.58%\n",
            "Epoch 42/150, Train Loss: 1.6240, Val Loss: 2.2321, Test Loss: 2.2268\n",
            "Epoch 43/150, Train Acc: 55.12%, Val Acc: 45.43%, Test Acc: 45.07%\n",
            "Epoch 43/150, Train Loss: 1.6041, Val Loss: 2.2073, Test Loss: 2.2086\n",
            "Epoch 44/150, Train Acc: 54.79%, Val Acc: 45.52%, Test Acc: 45.37%\n",
            "Epoch 44/150, Train Loss: 1.5993, Val Loss: 2.1704, Test Loss: 2.1789\n",
            "Epoch 45/150, Train Acc: 55.64%, Val Acc: 46.05%, Test Acc: 45.70%\n",
            "Epoch 45/150, Train Loss: 1.5806, Val Loss: 2.1769, Test Loss: 2.1995\n",
            "Epoch 46/150, Train Acc: 55.66%, Val Acc: 45.65%, Test Acc: 45.75%\n",
            "Epoch 46/150, Train Loss: 1.5758, Val Loss: 2.1895, Test Loss: 2.1909\n",
            "Epoch 47/150, Train Acc: 55.60%, Val Acc: 45.33%, Test Acc: 45.30%\n",
            "Epoch 47/150, Train Loss: 1.5645, Val Loss: 2.2070, Test Loss: 2.2053\n",
            "Epoch 48/150, Train Acc: 56.24%, Val Acc: 44.97%, Test Acc: 45.01%\n",
            "Epoch 48/150, Train Loss: 1.5413, Val Loss: 2.2191, Test Loss: 2.2206\n",
            "Epoch 49/150, Train Acc: 56.09%, Val Acc: 45.73%, Test Acc: 45.97%\n",
            "Epoch 49/150, Train Loss: 1.5474, Val Loss: 2.2163, Test Loss: 2.2101\n",
            "Checkpoint saved at epoch 50: ./checkpoint_epoch_50.pth\n",
            "Epoch 50/150, Train Acc: 56.43%, Val Acc: 45.67%, Test Acc: 45.43%\n",
            "Epoch 50/150, Train Loss: 1.5401, Val Loss: 2.2229, Test Loss: 2.2187\n",
            "Epoch 51/150, Train Acc: 56.94%, Val Acc: 45.47%, Test Acc: 45.45%\n",
            "Epoch 51/150, Train Loss: 1.5182, Val Loss: 2.2324, Test Loss: 2.2320\n",
            "Epoch 52/150, Train Acc: 56.98%, Val Acc: 46.38%, Test Acc: 46.21%\n",
            "Epoch 52/150, Train Loss: 1.5091, Val Loss: 2.1978, Test Loss: 2.1934\n",
            "Epoch 53/150, Train Acc: 57.45%, Val Acc: 45.50%, Test Acc: 45.14%\n",
            "Epoch 53/150, Train Loss: 1.4998, Val Loss: 2.2252, Test Loss: 2.2382\n",
            "Epoch 54/150, Train Acc: 57.87%, Val Acc: 45.57%, Test Acc: 45.68%\n",
            "Epoch 54/150, Train Loss: 1.4845, Val Loss: 2.2070, Test Loss: 2.2111\n",
            "Epoch 55/150, Train Acc: 58.27%, Val Acc: 45.80%, Test Acc: 45.60%\n",
            "Epoch 55/150, Train Loss: 1.4749, Val Loss: 2.2060, Test Loss: 2.2254\n",
            "Epoch 56/150, Train Acc: 58.62%, Val Acc: 46.47%, Test Acc: 45.97%\n",
            "Epoch 56/150, Train Loss: 1.4657, Val Loss: 2.2006, Test Loss: 2.1990\n",
            "Epoch 57/150, Train Acc: 58.19%, Val Acc: 46.48%, Test Acc: 46.32%\n",
            "Epoch 57/150, Train Loss: 1.4583, Val Loss: 2.1814, Test Loss: 2.1883\n",
            "Epoch 58/150, Train Acc: 58.98%, Val Acc: 46.25%, Test Acc: 45.95%\n",
            "Epoch 58/150, Train Loss: 1.4440, Val Loss: 2.2412, Test Loss: 2.2388\n",
            "Epoch 59/150, Train Acc: 58.93%, Val Acc: 46.76%, Test Acc: 46.30%\n",
            "Epoch 59/150, Train Loss: 1.4390, Val Loss: 2.2396, Test Loss: 2.2591\n",
            "Checkpoint saved at epoch 60: ./checkpoint_epoch_60.pth\n",
            "Epoch 60/150, Train Acc: 59.12%, Val Acc: 45.74%, Test Acc: 45.57%\n",
            "Epoch 60/150, Train Loss: 1.4268, Val Loss: 2.2797, Test Loss: 2.2774\n",
            "Epoch 61/150, Train Acc: 59.29%, Val Acc: 46.44%, Test Acc: 46.39%\n",
            "Epoch 61/150, Train Loss: 1.4200, Val Loss: 2.1982, Test Loss: 2.2064\n",
            "Epoch 62/150, Train Acc: 59.50%, Val Acc: 46.69%, Test Acc: 46.48%\n",
            "Epoch 62/150, Train Loss: 1.4146, Val Loss: 2.2142, Test Loss: 2.2263\n",
            "Epoch 63/150, Train Acc: 59.89%, Val Acc: 46.24%, Test Acc: 45.90%\n",
            "Epoch 63/150, Train Loss: 1.3968, Val Loss: 2.2447, Test Loss: 2.2528\n",
            "Epoch 64/150, Train Acc: 60.05%, Val Acc: 46.20%, Test Acc: 45.75%\n",
            "Epoch 64/150, Train Loss: 1.3908, Val Loss: 2.2500, Test Loss: 2.2651\n",
            "Epoch 65/150, Train Acc: 60.65%, Val Acc: 46.15%, Test Acc: 45.85%\n",
            "Epoch 65/150, Train Loss: 1.3732, Val Loss: 2.2865, Test Loss: 2.2847\n",
            "Epoch 66/150, Train Acc: 60.26%, Val Acc: 46.51%, Test Acc: 46.62%\n",
            "Epoch 66/150, Train Loss: 1.3789, Val Loss: 2.2378, Test Loss: 2.2442\n",
            "Epoch 67/150, Train Acc: 60.64%, Val Acc: 46.87%, Test Acc: 47.00%\n",
            "Epoch 67/150, Train Loss: 1.3703, Val Loss: 2.2347, Test Loss: 2.2265\n",
            "Epoch 68/150, Train Acc: 60.89%, Val Acc: 46.82%, Test Acc: 46.52%\n",
            "Epoch 68/150, Train Loss: 1.3562, Val Loss: 2.2452, Test Loss: 2.2314\n",
            "Epoch 69/150, Train Acc: 61.25%, Val Acc: 46.73%, Test Acc: 46.47%\n",
            "Epoch 69/150, Train Loss: 1.3371, Val Loss: 2.2603, Test Loss: 2.2611\n",
            "Checkpoint saved at epoch 70: ./checkpoint_epoch_70.pth\n",
            "Epoch 70/150, Train Acc: 61.24%, Val Acc: 46.91%, Test Acc: 47.19%\n",
            "Epoch 70/150, Train Loss: 1.3442, Val Loss: 2.2624, Test Loss: 2.2514\n",
            "Epoch 71/150, Train Acc: 61.70%, Val Acc: 46.16%, Test Acc: 46.32%\n",
            "Epoch 71/150, Train Loss: 1.3332, Val Loss: 2.2735, Test Loss: 2.2698\n",
            "Epoch 72/150, Train Acc: 61.69%, Val Acc: 46.80%, Test Acc: 46.34%\n",
            "Epoch 72/150, Train Loss: 1.3231, Val Loss: 2.2561, Test Loss: 2.2578\n",
            "Epoch 73/150, Train Acc: 62.03%, Val Acc: 46.93%, Test Acc: 46.65%\n",
            "Epoch 73/150, Train Loss: 1.3137, Val Loss: 2.2632, Test Loss: 2.2718\n",
            "Epoch 74/150, Train Acc: 62.16%, Val Acc: 46.69%, Test Acc: 47.39%\n",
            "Epoch 74/150, Train Loss: 1.3057, Val Loss: 2.2361, Test Loss: 2.2297\n",
            "Epoch 75/150, Train Acc: 62.75%, Val Acc: 46.63%, Test Acc: 46.80%\n",
            "Epoch 75/150, Train Loss: 1.2945, Val Loss: 2.2916, Test Loss: 2.2702\n",
            "Epoch 76/150, Train Acc: 62.80%, Val Acc: 46.50%, Test Acc: 46.76%\n",
            "Epoch 76/150, Train Loss: 1.2848, Val Loss: 2.2845, Test Loss: 2.2786\n",
            "Epoch 77/150, Train Acc: 62.92%, Val Acc: 46.84%, Test Acc: 46.50%\n",
            "Epoch 77/150, Train Loss: 1.2783, Val Loss: 2.2638, Test Loss: 2.2594\n",
            "Epoch 78/150, Train Acc: 62.87%, Val Acc: 46.91%, Test Acc: 46.42%\n",
            "Epoch 78/150, Train Loss: 1.2750, Val Loss: 2.2791, Test Loss: 2.2802\n",
            "Epoch 79/150, Train Acc: 63.29%, Val Acc: 47.08%, Test Acc: 46.93%\n",
            "Epoch 79/150, Train Loss: 1.2708, Val Loss: 2.2592, Test Loss: 2.2637\n",
            "Checkpoint saved at epoch 80: ./checkpoint_epoch_80.pth\n",
            "Epoch 80/150, Train Acc: 63.59%, Val Acc: 47.00%, Test Acc: 47.05%\n",
            "Epoch 80/150, Train Loss: 1.2549, Val Loss: 2.2761, Test Loss: 2.2838\n",
            "Epoch 81/150, Train Acc: 63.62%, Val Acc: 47.05%, Test Acc: 47.36%\n",
            "Epoch 81/150, Train Loss: 1.2447, Val Loss: 2.2951, Test Loss: 2.2861\n",
            "Epoch 82/150, Train Acc: 64.18%, Val Acc: 47.05%, Test Acc: 47.20%\n",
            "Epoch 82/150, Train Loss: 1.2341, Val Loss: 2.2788, Test Loss: 2.2763\n",
            "Epoch 83/150, Train Acc: 64.36%, Val Acc: 47.26%, Test Acc: 47.30%\n",
            "Epoch 83/150, Train Loss: 1.2274, Val Loss: 2.3015, Test Loss: 2.2918\n",
            "Epoch 84/150, Train Acc: 64.54%, Val Acc: 46.83%, Test Acc: 46.87%\n",
            "Epoch 84/150, Train Loss: 1.2207, Val Loss: 2.2949, Test Loss: 2.2853\n",
            "Epoch 85/150, Train Acc: 64.48%, Val Acc: 46.90%, Test Acc: 47.23%\n",
            "Epoch 85/150, Train Loss: 1.2183, Val Loss: 2.2689, Test Loss: 2.2571\n",
            "Epoch 86/150, Train Acc: 64.36%, Val Acc: 47.41%, Test Acc: 47.40%\n",
            "Epoch 86/150, Train Loss: 1.2172, Val Loss: 2.2982, Test Loss: 2.2825\n",
            "Epoch 87/150, Train Acc: 64.72%, Val Acc: 47.28%, Test Acc: 46.87%\n",
            "Epoch 87/150, Train Loss: 1.2009, Val Loss: 2.3287, Test Loss: 2.3196\n",
            "Epoch 88/150, Train Acc: 65.35%, Val Acc: 46.75%, Test Acc: 47.48%\n",
            "Epoch 88/150, Train Loss: 1.1901, Val Loss: 2.3331, Test Loss: 2.3326\n",
            "Epoch 89/150, Train Acc: 65.48%, Val Acc: 47.00%, Test Acc: 47.22%\n",
            "Epoch 89/150, Train Loss: 1.1865, Val Loss: 2.3188, Test Loss: 2.3083\n",
            "Checkpoint saved at epoch 90: ./checkpoint_epoch_90.pth\n",
            "Epoch 90/150, Train Acc: 65.83%, Val Acc: 47.02%, Test Acc: 48.00%\n",
            "Epoch 90/150, Train Loss: 1.1803, Val Loss: 2.3359, Test Loss: 2.3207\n",
            "Epoch 91/150, Train Acc: 65.75%, Val Acc: 47.26%, Test Acc: 47.41%\n",
            "Epoch 91/150, Train Loss: 1.1781, Val Loss: 2.3252, Test Loss: 2.3234\n",
            "Epoch 92/150, Train Acc: 66.30%, Val Acc: 47.49%, Test Acc: 47.20%\n",
            "Epoch 92/150, Train Loss: 1.1609, Val Loss: 2.3207, Test Loss: 2.3173\n",
            "Epoch 93/150, Train Acc: 65.94%, Val Acc: 47.50%, Test Acc: 47.69%\n",
            "Epoch 93/150, Train Loss: 1.1633, Val Loss: 2.3352, Test Loss: 2.3449\n",
            "Epoch 94/150, Train Acc: 66.58%, Val Acc: 47.52%, Test Acc: 47.58%\n",
            "Epoch 94/150, Train Loss: 1.1451, Val Loss: 2.3263, Test Loss: 2.3295\n",
            "Epoch 95/150, Train Acc: 66.26%, Val Acc: 46.98%, Test Acc: 47.71%\n",
            "Epoch 95/150, Train Loss: 1.1494, Val Loss: 2.3308, Test Loss: 2.3285\n",
            "Epoch 96/150, Train Acc: 66.82%, Val Acc: 47.49%, Test Acc: 47.56%\n",
            "Epoch 96/150, Train Loss: 1.1312, Val Loss: 2.3228, Test Loss: 2.3220\n",
            "Epoch 97/150, Train Acc: 66.68%, Val Acc: 47.88%, Test Acc: 47.63%\n",
            "Epoch 97/150, Train Loss: 1.1393, Val Loss: 2.3171, Test Loss: 2.3195\n",
            "Epoch 98/150, Train Acc: 67.01%, Val Acc: 47.40%, Test Acc: 48.15%\n",
            "Epoch 98/150, Train Loss: 1.1234, Val Loss: 2.3254, Test Loss: 2.3190\n",
            "Epoch 99/150, Train Acc: 67.22%, Val Acc: 47.09%, Test Acc: 47.69%\n",
            "Epoch 99/150, Train Loss: 1.1180, Val Loss: 2.3449, Test Loss: 2.3375\n",
            "Checkpoint saved at epoch 100: ./checkpoint_epoch_100.pth\n",
            "Epoch 100/150, Train Acc: 67.60%, Val Acc: 47.54%, Test Acc: 47.95%\n",
            "Epoch 100/150, Train Loss: 1.1109, Val Loss: 2.3325, Test Loss: 2.3441\n",
            "Epoch 101/150, Train Acc: 67.60%, Val Acc: 47.69%, Test Acc: 47.66%\n",
            "Epoch 101/150, Train Loss: 1.1081, Val Loss: 2.3347, Test Loss: 2.3382\n",
            "Epoch 102/150, Train Acc: 67.52%, Val Acc: 47.46%, Test Acc: 47.73%\n",
            "Epoch 102/150, Train Loss: 1.1016, Val Loss: 2.3478, Test Loss: 2.3397\n",
            "Epoch 103/150, Train Acc: 67.93%, Val Acc: 46.80%, Test Acc: 47.31%\n",
            "Epoch 103/150, Train Loss: 1.0900, Val Loss: 2.3500, Test Loss: 2.3465\n",
            "Epoch 104/150, Train Acc: 68.00%, Val Acc: 47.59%, Test Acc: 47.92%\n",
            "Epoch 104/150, Train Loss: 1.0946, Val Loss: 2.3377, Test Loss: 2.3293\n",
            "Epoch 105/150, Train Acc: 68.25%, Val Acc: 47.18%, Test Acc: 47.39%\n",
            "Epoch 105/150, Train Loss: 1.0819, Val Loss: 2.3396, Test Loss: 2.3543\n",
            "Epoch 106/150, Train Acc: 68.42%, Val Acc: 47.43%, Test Acc: 47.99%\n",
            "Epoch 106/150, Train Loss: 1.0813, Val Loss: 2.3388, Test Loss: 2.3412\n",
            "Epoch 107/150, Train Acc: 68.48%, Val Acc: 47.49%, Test Acc: 47.84%\n",
            "Epoch 107/150, Train Loss: 1.0743, Val Loss: 2.3363, Test Loss: 2.3365\n",
            "Epoch 108/150, Train Acc: 68.34%, Val Acc: 47.01%, Test Acc: 47.96%\n",
            "Epoch 108/150, Train Loss: 1.0783, Val Loss: 2.3599, Test Loss: 2.3575\n",
            "Epoch 109/150, Train Acc: 68.83%, Val Acc: 47.22%, Test Acc: 48.14%\n",
            "Epoch 109/150, Train Loss: 1.0579, Val Loss: 2.3723, Test Loss: 2.3619\n",
            "Checkpoint saved at epoch 110: ./checkpoint_epoch_110.pth\n",
            "Epoch 110/150, Train Acc: 68.98%, Val Acc: 47.27%, Test Acc: 48.07%\n",
            "Epoch 110/150, Train Loss: 1.0585, Val Loss: 2.3434, Test Loss: 2.3335\n",
            "Epoch 111/150, Train Acc: 69.19%, Val Acc: 47.45%, Test Acc: 47.69%\n",
            "Epoch 111/150, Train Loss: 1.0492, Val Loss: 2.3602, Test Loss: 2.3622\n",
            "Epoch 112/150, Train Acc: 69.28%, Val Acc: 47.49%, Test Acc: 47.68%\n",
            "Epoch 112/150, Train Loss: 1.0491, Val Loss: 2.3556, Test Loss: 2.3575\n",
            "Epoch 113/150, Train Acc: 69.59%, Val Acc: 47.21%, Test Acc: 47.70%\n",
            "Epoch 113/150, Train Loss: 1.0401, Val Loss: 2.3781, Test Loss: 2.3870\n",
            "Epoch 114/150, Train Acc: 69.62%, Val Acc: 46.96%, Test Acc: 47.76%\n",
            "Epoch 114/150, Train Loss: 1.0356, Val Loss: 2.3881, Test Loss: 2.3847\n",
            "Epoch 115/150, Train Acc: 69.69%, Val Acc: 47.18%, Test Acc: 47.76%\n",
            "Epoch 115/150, Train Loss: 1.0351, Val Loss: 2.3619, Test Loss: 2.3538\n",
            "Epoch 116/150, Train Acc: 69.71%, Val Acc: 47.40%, Test Acc: 48.20%\n",
            "Epoch 116/150, Train Loss: 1.0284, Val Loss: 2.3787, Test Loss: 2.3677\n",
            "Epoch 117/150, Train Acc: 69.80%, Val Acc: 47.30%, Test Acc: 47.85%\n",
            "Epoch 117/150, Train Loss: 1.0287, Val Loss: 2.3867, Test Loss: 2.3859\n",
            "Epoch 118/150, Train Acc: 69.79%, Val Acc: 47.16%, Test Acc: 47.96%\n",
            "Epoch 118/150, Train Loss: 1.0210, Val Loss: 2.3905, Test Loss: 2.3796\n",
            "Epoch 119/150, Train Acc: 70.20%, Val Acc: 47.26%, Test Acc: 47.38%\n",
            "Epoch 119/150, Train Loss: 1.0166, Val Loss: 2.3989, Test Loss: 2.3950\n",
            "Checkpoint saved at epoch 120: ./checkpoint_epoch_120.pth\n",
            "Epoch 120/150, Train Acc: 70.13%, Val Acc: 47.45%, Test Acc: 48.01%\n",
            "Epoch 120/150, Train Loss: 1.0142, Val Loss: 2.3811, Test Loss: 2.3822\n",
            "Epoch 121/150, Train Acc: 69.93%, Val Acc: 47.63%, Test Acc: 48.15%\n",
            "Epoch 121/150, Train Loss: 1.0141, Val Loss: 2.3751, Test Loss: 2.3740\n",
            "Epoch 122/150, Train Acc: 70.26%, Val Acc: 47.58%, Test Acc: 48.02%\n",
            "Epoch 122/150, Train Loss: 1.0058, Val Loss: 2.3824, Test Loss: 2.3832\n",
            "Epoch 123/150, Train Acc: 70.49%, Val Acc: 47.73%, Test Acc: 48.27%\n",
            "Epoch 123/150, Train Loss: 1.0058, Val Loss: 2.3899, Test Loss: 2.3844\n",
            "Epoch 124/150, Train Acc: 70.62%, Val Acc: 47.70%, Test Acc: 48.11%\n",
            "Epoch 124/150, Train Loss: 1.0009, Val Loss: 2.3867, Test Loss: 2.3892\n",
            "Epoch 125/150, Train Acc: 70.61%, Val Acc: 47.45%, Test Acc: 47.91%\n",
            "Epoch 125/150, Train Loss: 0.9971, Val Loss: 2.3895, Test Loss: 2.3928\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8613a36b3d30>\u001b[0m in \u001b[0;36m<cell line: 215>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Train with AdamW ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m \u001b[0madamw_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madamw_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madamw_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madamw_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madamw_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madamw_test_acc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madamw_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_adamw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_adamw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8613a36b3d30>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, scheduler, model, criterion, trainloader, valloader, testloader, device, epochs, save_checkpoint_interval)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split\n",
        "from google.colab import files\n",
        "\n",
        "# Training settings\n",
        "# betas, epochs and batch sized are fixed values\n",
        "epochs = 150\n",
        "batch_size = 64\n",
        "# weight decay and learning rate are adjustable\n",
        "weight_decay = 1e-5\n",
        "lr= 2e-3\n",
        "\n",
        "def compute_mean_std(dataset):\n",
        "    \"\"\"Compute the mean and std of CIFAR-100 dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: A dataset derived from `torch.utils.data.Dataset`,\n",
        "                 such as `cifar100_training_dataset` or `cifar100_test_dataset`.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing (mean, std) for the entire dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract images and labels\n",
        "    data_r = np.stack([np.array(dataset[i][0])[:, :, 0] for i in range(len(dataset))])\n",
        "    data_g = np.stack([np.array(dataset[i][0])[:, :, 1] for i in range(len(dataset))])\n",
        "    data_b = np.stack([np.array(dataset[i][0])[:, :, 2] for i in range(len(dataset))])\n",
        "\n",
        "    # Compute mean and std\n",
        "    mean = np.mean(data_r), np.mean(data_g), np.mean(data_b)\n",
        "    std = np.std(data_r), np.std(data_g), np.std(data_b)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "# Define LeNet-5 architecture\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 5 * 5)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42) # Set the seed for reproducibility\n",
        "torch.cuda.manual_seed_all(42) # Set the seed for reproducibility on GPU\n",
        "\n",
        "# use the same mean and std to add consistency to all datasets\n",
        "data = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mean, std = compute_mean_std(data)\n",
        "\n",
        "# Load and split CIFAR-100 dataset\n",
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert into tensor\n",
        "    transforms.Normalize(mean, std)  # Normalization\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "valset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=val_transform)\n",
        "indices = torch.randperm(len(trainset))\n",
        "val_size = int(0.2*len(trainset))\n",
        "trainset = torch.utils.data.Subset(trainset, indices[:-val_size])\n",
        "valset = torch.utils.data.Subset(valset, indices[-val_size:])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model\n",
        "net_adamw = LeNet5().to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer and scheduler\n",
        "adamw_optimizer = optim.AdamW(net_adamw.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
        "scheduler_adamw = optim.lr_scheduler.CosineAnnealingLR(adamw_optimizer, T_max=150)\n",
        "'''\n",
        "# Load a checkpoint, if exists\n",
        "resume_training = True  # Put False if you want to start from scratch\n",
        "start_epoch = 0  # default starting epoch\n",
        "\n",
        "if resume_training and os.path.exists('checkpoint_epoch_30.pth'):\n",
        "    checkpoint = torch.load('checkpoint_epoch_30.pth', map_location=device)\n",
        "    net_adamw.load_state_dict(checkpoint['model_state_dict'])\n",
        "    adamw_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"Checkpoint caricato: riprendo da epoca {start_epoch}\")\n",
        "else:\n",
        "    print(\"Nessun checkpoint trovato, inizializzo da zero.\")\n",
        "'''\n",
        "\n",
        "# Training function\n",
        "def train_model(optimizer, scheduler, model, criterion, trainloader, valloader , testloader, device, epochs, save_checkpoint_interval=10):\n",
        "    train_losses, val_losses, test_losses = [], [], []\n",
        "    train_accuracies, val_accuracies, test_accuracies = [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += predicted.eq(labels).sum().item()\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_accuracy = 100. * correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct_val, total_val, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += predicted.eq(labels).sum().item()\n",
        "        val_loss /= len(valloader)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracy = 100. * correct_val / total_val\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Test\n",
        "        correct_test, total_test, test_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += predicted.eq(labels).sum().item()\n",
        "        test_loss /= len(testloader)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracy = 100. * correct_test / total_test\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Checkpointing\n",
        "        if (epoch + 1) % save_checkpoint_interval == 0:\n",
        "            checkpoint_filename = f'checkpoint_epoch_{epoch + 1}.pth'\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss.item(),\n",
        "            }\n",
        "            checkpoint_path = os.path.join('./', checkpoint_filename)\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f'Checkpoint saved at epoch {epoch + 1}: {checkpoint_path}')\n",
        "\n",
        "            #Download the checkpoint\n",
        "            #files.download(checkpoint_filename)\n",
        "\n",
        "        # print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%')\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "    return train_losses, val_losses, test_losses,  train_accuracies, val_accuracies, test_accuracies\n",
        "\n",
        "# Train model\n",
        "print(\"--- Train with AdamW ---\")\n",
        "adamw_train_loss, adamw_val_loss, adamw_test_loss, adamw_train_acc, adamw_val_acc, adamw_test_acc= train_model(adamw_optimizer, scheduler_adamw, net_adamw, criterion, trainloader, valloader, testloader, device, epochs)\n",
        "\n",
        "# Save model\n",
        "torch.save(net_adamw.state_dict(), 'net_adamw.pth')\n",
        "\n",
        "# Plot results\n",
        "# Plot Training Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_train_loss, label='Train Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Training Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_train_acc, label='Train Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_val_loss, label='Validation Loss')\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('val_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_val_acc, label='Validation Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('val_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_test_loss, label='Test Loss')\n",
        "plt.title('Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_loss.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracy\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(adamw_test_acc, label='Test Accuracy')\n",
        "plt.title('Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_accuracy.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}